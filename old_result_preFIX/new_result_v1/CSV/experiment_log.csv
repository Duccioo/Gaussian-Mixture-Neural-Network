Date,Id,Components,Model,Pdf Type,Samples,Dimension,R2 Score,Mse Score,Max Error Score,Evs Score,Ise Score,K1 Score,Best Params,Experiment Params,Epoch,Pdf Param,Id Dataset
2023-08-31 20:24:34,42684,32,GMM random,exponential,100,1,0.773,0.191,1.261,0.773,400.988,0.758,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-08-31 20:24:39,a1e86,32,MLP kmeans ,exponential,100,1,0.719,0.212,1.105,0.73,0.153,0.198,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 100], 'batch_size': [8, 32, 128], 'lr': [0.003, 0.01], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU())], [(64, Tanh())], [(80, ReLU()), (160, ReLU())], [(16, Tanh()), (32, Tanh()), (64, ReLU())], [(16, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (32, ReLU())], [(32, ReLU()), (16, Tanh()), (8, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.5, 0.1]}",327,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-08-31 20:26:25,4b60e,32,MLP kmeans ,exponential,100,1,0.703,0.219,1.064,0.732,0.162,1.882,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 100], 'batch_size': [8, 32, 128], 'lr': [0.003, 0.01], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(64, Tanh())], [(64, ReLU()), (128, ReLU())], [(16, Tanh()), (32, Tanh()), (64, ReLU())], [(8, LeakyReLU(negative_slope=0.01)), (16, Tanh()), (32, ReLU())], [(32, ReLU()), (16, Tanh()), (8, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.5, 0.1]}",500,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-08-31 20:27:25,eb89f,32,GMM random,multivariate,100,1,0.966,0.008,0.031,0.966,384.313,0.693,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-08-31 20:27:34,80963,32,MLP kmeans ,multivariate,100,1,0.069,0.04,0.105,0.084,0.055,3.766,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 100], 'batch_size': [8, 32, 128], 'lr': [0.001, 0.01], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(64, Tanh())], [(64, ReLU()), (128, ReLU())], [(16, Tanh()), (32, Tanh()), (64, ReLU())], [(8, LeakyReLU(negative_slope=0.01)), (16, Tanh()), (32, ReLU())], [(32, ReLU()), (16, Tanh()), (8, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>, <class 'torch.optim.sgd.SGD'>], 'module__dropout': [0.5, 0.1]}",500,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-08-31 20:27:49,c1d44,32,GMM kmeans,multivariate,100,1,-0.934,0.057,1.869,-0.932,788.27,0.693,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-08-31 20:28:21,e4a7d,32,MLP random ,multivariate,100,1,0.935,0.01,0.045,0.936,0.004,0.043,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 100], 'batch_size': [8, 32, 128], 'lr': [0.001, 0.01], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(64, Tanh())], [(64, ReLU()), (128, ReLU())], [(16, Tanh()), (32, Tanh()), (64, ReLU())], [(8, LeakyReLU(negative_slope=0.01)), (16, Tanh()), (32, ReLU())], [(32, ReLU()), (16, Tanh()), (8, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>, <class 'torch.optim.sgd.SGD'>], 'module__dropout': [0.5, 0.1]}",500,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-08-31 20:49:03,82dff,32,MLP random ,multivariate,100,1,0.948,0.009,0.043,0.95,0.003,0.032,"{'batch_size': 8, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.001, 'max_epochs': 1000, 'module__dropout': 0.1, 'module__hidden_layer': [(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 100], 'batch_size': [8, 32, 128], 'lr': [0.001, 0.01], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(64, Tanh())], [(64, ReLU()), (128, ReLU())], [(16, Tanh()), (32, Tanh()), (64, ReLU())], [(8, LeakyReLU(negative_slope=0.01)), (16, Tanh()), (32, ReLU())], [(32, ReLU()), (16, Tanh()), (8, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>, <class 'torch.optim.sgd.SGD'>], 'module__dropout': [0.5, 0.1]}",1000,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-08-31 21:16:39,6011f,32,MLP random ,multivariate,100,1,-1.063,0.059,0.103,0.125,0.121,0.565,"{'batch_size': 32, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.001, 'max_epochs': 5000, 'module__dropout': 0.3, 'module__hidden_layer': [(128, ReLU()), (64, ReLU()), (128, ReLU())], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>, 'optimizer__weight_decay': 0.001}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(128, ReLU()), (64, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'optimizer__weight_decay': [0.001], 'module__dropout': [0.3, 0.1]}",5000,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-08-31 22:01:25,ede80,32,MLP random ,multivariate,100,1,0.963,0.008,0.036,0.964,0.002,0.023,"{'batch_size': 16, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.001, 'max_epochs': 5000, 'module__dropout': 0.2, 'module__hidden_layer': [(128, ReLU()), (128, ReLU()), (128, ReLU())], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",5000,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 03:16:58,8a1d6,32,MLP random ,exponential,100,1,0.758,0.197,1.174,0.759,0.132,0.148,"{'batch_size': 8, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.002, 'max_epochs': 1000, 'module__dropout': 0.1, 'module__hidden_layer': [(64, Tanh()), (32, Tanh()), (128, ReLU())], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",1000,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 13:12:32,b6905,32,MLP random ,multivariate,100,1,0.935,0.01,0.045,0.936,0.004,0.043,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",500,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:14:21,b9a8d,32,MLP random ,multivariate,100,1,-0.616,0.052,0.106,-0.353,0.095,0.616,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:15:03,0ddd3,32,MLP random ,multivariate,100,1,-0.369,0.048,0.215,-0.117,0.08,1.977,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [4, 8, 32, 16], 'lr': [0.003, 0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",100,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:15:37,81412,32,MLP random ,multivariate,100,1,-1.918,0.07,0.114,0.142,0.171,0.626,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [4, 8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(12, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'optimizer__weight_decay': [0.001], 'module__dropout': [0.2, 0.1]}",100,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:17:12,82a9b,32,MLP random ,multivariate,100,1,-1.474,0.064,0.127,0.047,0.145,0.643,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [1000, 1000, 5000], 'batch_size': [4, 8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, Tanh()), (64, Tanh()), (32, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, <class 'torch.nn.modules.activation.Tanh'>)], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'optimizer__weight_decay': [0.001], 'module__dropout': [0.2, 0.1]}",690,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:18:18,cc140,32,MLP random ,multivariate,100,1,-1.475,0.064,0.127,0.045,0.145,0.643,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [1000, 1000, 5000], 'batch_size': [4, 8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, ReLU()), (64, Tanh()), (128, Tanh()), (64, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'optimizer__weight_decay': [0.001], 'module__dropout': [0.2, 0.1]}",305,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:18:56,378ee,32,MLP random ,multivariate,100,1,0.963,0.008,0.034,0.964,0.002,0.02,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [1000, 1000, 5000], 'batch_size': [4, 8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, ReLU()), (64, Tanh()), (128, Tanh()), (64, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",1000,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:20:43,8dc8d,32,MLP random ,multivariate,100,1,0.875,0.014,0.04,0.885,0.007,0.161,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, ReLU()), (64, Tanh()), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",500,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:21:16,abd73,32,MLP kmeans ,multivariate,100,1,-0.027,0.042,0.106,0.127,0.06,0.544,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, ReLU()), (64, Tanh()), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",500,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:21:41,c7fe5,32,MLP random_from_data ,multivariate,100,1,0.283,0.035,0.08,0.34,0.042,0.51,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, ReLU()), (64, Tanh()), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",500,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:21:58,c4576,32,GMM random_from_data,multivariate,100,1,-2.199,0.073,3.379,-2.198,1031.405,0.693,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:47:05,82ff2,4,GMM random,multivariate,100,1,0.971,0.007,0.032,0.971,382.147,0.693,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:47:12,15451,4,MLP random ,multivariate,100,1,-1.356,0.063,0.126,-0.596,0.138,0.646,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, ReLU()), (64, Tanh()), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",100,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:47:40,84993,4,MLP random ,multivariate,100,1,0.759,0.02,0.043,0.795,0.014,0.235,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [300, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, ReLU()), (64, Tanh()), (64, Tanh()), (16, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",300,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:48:26,74336,4,MLP random ,multivariate,100,1,0.681,0.023,0.059,0.738,0.019,0.255,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [300, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, Tanh()), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",300,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:48:51,608bf,4,MLP random ,multivariate,100,1,-0.468,0.05,0.216,-0.102,0.086,7.348,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [300, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",300,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:49:10,d08ee,4,MLP random ,multivariate,100,1,0.894,0.013,0.042,0.894,0.006,0.116,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [300, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, Tanh()), (32, Tanh()), (32, ReLU()), (16, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",300,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:49:39,51c1c,4,MLP random ,multivariate,100,1,0.875,0.015,0.045,0.878,0.007,0.113,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [300, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, Tanh()), (32, ReLU()), (32, ReLU()), (16, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",300,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:50:07,14f70,4,MLP random ,multivariate,100,1,0.716,0.022,0.043,0.767,0.017,0.267,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [300, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, ReLU()), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",300,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:50:37,6de5c,4,MLP random ,multivariate,100,1,0.947,0.009,0.037,0.948,0.003,0.035,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [300, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, ReLU()), (32, Tanh()), (32, ReLU()), (16, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",300,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:51:15,1b60b,4,MLP random ,multivariate,100,1,0.724,0.022,0.042,0.769,0.016,0.267,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [300, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, ReLU()), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01)), (8, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",300,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:51:52,ad64f,4,MLP random ,multivariate,100,1,0.9,0.013,0.045,0.907,0.006,0.124,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [300, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, ReLU()), (64, Tanh()), (32, LeakyReLU(negative_slope=0.01)), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",300,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:52:33,e9183,4,MLP random ,multivariate,100,1,0.902,0.013,0.046,0.908,0.006,0.12,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [300, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (32, LeakyReLU(negative_slope=0.01)), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",300,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:53:03,eee95,4,MLP random ,multivariate,100,1,0.939,0.01,0.049,0.94,0.004,0.035,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [300, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (128, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",300,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:53:30,4415f,4,MLP random ,multivariate,100,1,0.934,0.011,0.048,0.934,0.004,0.061,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (128, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:54:02,7fbd5,4,MLP kmeans ,multivariate,100,1,0.71,0.022,0.105,0.71,0.017,0.204,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (128, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:55:26,a760d,4,MLP random ,multivariate,100,1,0.947,0.009,0.044,0.947,0.003,0.041,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:55:46,8a521,4,MLP random ,multivariate,100,1,0.732,0.021,0.093,0.735,0.016,0.207,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",cc6b1
2023-09-01 13:56:08,afa4b,4,GMM random,multivariate,10,1,0.583,0.029,0.119,0.584,167.579,0.421,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",3770c
2023-09-01 13:56:10,cd1c6,4,MLP random ,multivariate,10,1,0.245,0.039,0.168,0.285,0.035,0.216,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",3770c
2023-09-01 13:56:55,f521a,4,MLP random ,multivariate,10,1,0.269,0.039,0.166,0.345,0.034,0.183,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",3770c
2023-09-01 13:57:08,93668,4,MLP random ,multivariate,10,1,0.253,0.039,0.166,0.388,0.035,0.325,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",500,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",3770c
2023-09-01 14:04:18,01947,4,GMM random,multivariate,10,1,0.095,0.036,0.168,0.095,150.693,0.504,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",28f0e
2023-09-01 14:04:23,9e0a8,4,MLP random ,multivariate,10,1,-0.086,0.039,0.189,0.049,0.049,0.437,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",500,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",28f0e
2023-09-01 14:04:38,b3a37,4,GMM random,multivariate,100,1,0.135,0.033,0.164,0.135,208.43,0.553,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-01 14:04:56,be4b8,4,MLP random ,multivariate,100,1,0.134,0.033,0.164,0.136,0.041,0.428,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",500,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-01 14:05:46,79d83,4,MLP kmeans ,multivariate,100,1,0.866,0.013,0.043,0.87,0.006,0.105,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",500,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-01 14:06:07,307b7,4,GMM kmeans,multivariate,100,1,0.951,0.008,0.029,0.951,342.309,0.553,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-01 14:06:41,2af32,32,GMM kmeans,multivariate,100,1,-1.629,0.058,1.869,-1.629,809.054,0.553,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-01 14:07:15,4fd9f,32,MLP kmeans ,multivariate,100,1,-1.388,0.055,0.139,0.0,0.113,0.553,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",407,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-01 14:07:57,0c5de,4,GMM kmeans,exponential,100,1,0.731,0.208,1.223,0.731,404.378,0.758,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:08:16,73222,4,MLP kmeans ,exponential,100,1,0.574,0.262,1.435,0.582,0.232,0.173,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",330,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:08:47,9a8f7,4,MLP kmeans ,exponential,100,1,0.723,0.211,1.201,0.728,0.151,0.123,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (64, Tanh()), (32, LeakyReLU(negative_slope=0.01)), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",500,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:09:26,6d658,4,MLP kmeans ,exponential,100,1,0.563,0.265,1.436,0.566,0.238,0.204,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [500, 1000, 5000], 'batch_size': [16, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01)), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",500,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:10:07,261e4,4,MLP kmeans ,exponential,100,1,0.614,0.249,1.341,0.624,0.21,0.221,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01)), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:10:34,4cb44,4,MLP kmeans ,exponential,100,1,0.574,0.262,1.415,0.584,0.232,0.222,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, Tanh()), (64, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01)), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:10:54,cc730,4,MLP kmeans ,exponential,100,1,0.796,0.181,0.814,0.797,0.111,0.133,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, Tanh()), (32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01)), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:11:18,f3025,4,MLP kmeans ,exponential,100,1,0.581,0.26,1.424,0.588,0.228,0.182,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, Tanh()), (32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01)), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:11:39,2f366,4,MLP kmeans ,exponential,100,1,0.572,0.262,1.416,0.572,0.233,0.181,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (16, LeakyReLU(negative_slope=0.01)), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:12:02,c4bf5,4,MLP kmeans ,exponential,100,1,0.556,0.267,1.436,0.561,0.242,0.242,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, LeakyReLU(negative_slope=0.01)), (16, Tanh()), (8, LeakyReLU(negative_slope=0.01)), (4, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:12:32,8fe9e,4,MLP kmeans ,exponential,100,1,0.712,0.215,1.226,0.714,0.157,0.157,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, LeakyReLU(negative_slope=0.01)), (16, Tanh()), (8, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:13:11,34a6c,4,MLP kmeans ,exponential,100,1,0.645,0.239,1.397,0.646,0.194,0.144,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, LeakyReLU(negative_slope=0.01)), (16, Tanh()), (8, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:13:28,41a8c,8,GMM kmeans,exponential,100,1,0.737,0.205,1.381,0.737,420.734,0.758,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:13:40,9cb90,8,MLP kmeans ,exponential,100,1,0.62,0.247,1.437,0.62,0.207,0.166,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, LeakyReLU(negative_slope=0.01)), (16, Tanh()), (8, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:14:13,9ce7c,8,MLP kmeans ,exponential,100,1,0.601,0.253,1.459,0.602,0.217,0.168,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, ReLU()), (32, LeakyReLU(negative_slope=0.01)), (16, Tanh()), (8, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:14:35,f18bd,8,MLP kmeans ,exponential,100,1,0.61,0.25,1.449,0.611,0.212,0.165,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (8, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:14:49,1c3a8,32,GMM kmeans,exponential,100,1,-0.979,0.564,6.123,-0.979,729.319,nan,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:15:12,edb6e,32,MLP kmeans ,exponential,100,1,0.723,0.211,1.027,0.733,0.151,0.184,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (8, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:15:59,c3fff,32,MLP random ,exponential,100,1,0.588,0.257,1.476,0.591,0.224,0.181,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (8, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:16:26,ccb3f,32,MLP random ,exponential,100,1,0.596,0.255,1.472,0.608,0.22,0.187,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(8, ReLU()), (16, LeakyReLU(negative_slope=0.01)), (16, Tanh()), (8, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:16:40,c5e15,32,MLP random ,exponential,100,1,0.612,0.25,1.472,0.613,0.211,0.146,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(8, ReLU()), (16, LeakyReLU(negative_slope=0.01)), (16, LeakyReLU(negative_slope=0.01)), (8, LeakyReLU(negative_slope=0.01))], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:16:57,0c903,32,MLP random ,exponential,100,1,0.61,0.25,1.473,0.611,0.212,0.148,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(8, ReLU()), (16, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:17:27,bba17,32,MLP random ,exponential,100,1,0.619,0.248,1.464,0.621,0.208,0.142,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-01 14:18:05,a6154,32,GMM random,multivariate,100,1,0.135,0.033,0.164,0.135,208.448,0.553,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-01 14:18:11,bd614,32,MLP random ,multivariate,100,1,-0.558,0.044,0.207,-0.248,0.074,5.487,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-01 16:34:59,1dd21,32,GMM random,multivariate,100,1,-82684.375,0.519,1408.359,-82684.369,0.0,0.0,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}], [{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",05772
2023-09-01 17:17:29,64251,4,GMM random,multivariate,100,2,0.525,0.001,0.03,0.525,0.0,0.0,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}], [{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",05772
2023-09-01 17:18:12,c5259,16,GMM random,multivariate,100,2,-62.27,0.014,19.763,-62.27,0.0,0.0,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}], [{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",05772
2023-09-01 17:37:57,c2304,4,MLP random ,multivariate,100,2,-1707.418,0.075,0.429,-1547.239,0.0,0.0,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}], [{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",05772
2023-09-06 18:00:43,66c82,4,MLP random ,multivariate,100,1,-0.558,0.044,0.207,-0.247,0.0,0.0,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-06 18:01:37,c9a52,4,GMM random,multivariate,1000,1,0.247,0.028,0.161,0.247,0.0,0.0,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",93f67
2023-09-06 18:01:55,7d1b1,4,MLP random ,multivariate,1000,1,0.256,0.028,0.163,0.257,0.0,0.0,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",93f67
2023-09-06 18:03:29,b9a31,16,GMM random,multivariate,1000,1,0.247,0.028,0.161,0.247,0.0,0.0,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",93f67
2023-09-06 18:04:01,2dfcb,16,MLP random ,multivariate,1000,1,0.252,0.028,0.163,0.252,0.0,0.0,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",93f67
2023-09-06 18:07:15,f20ee,16,MLP kmeans ,multivariate,1000,1,0.48,0.023,0.083,0.521,0.0,0.0,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",93f67
2023-09-06 18:07:45,991ef,8,GMM random,multivariate,100,1,0.136,0.033,0.163,0.136,0.0,0.0,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-06 18:07:56,6189f,8,MLP kmeans ,multivariate,100,1,-1.336,0.054,0.12,-0.664,0.0,0.0,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-06 18:08:27,e89a9,8,MLP k-means++ ,multivariate,100,1,-0.98,0.05,0.115,-0.482,0.0,0.0,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",9dec7
2023-09-06 18:08:44,b25b0,8,GMM random,multivariate,1000,1,0.247,0.028,0.161,0.247,0.0,0.0,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",93f67
2023-09-06 18:11:41,c11f8,8,MLP kmeans ,exponential,100,1,0.655,0.236,1.405,0.655,0.0,0.0,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-06 18:45:12,d143d,8,MLP kmeans ,exponential,100,1,0.548,0.269,1.529,0.548,0.246,0.212,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-06 19:01:49,39ebe,8,MLP kmeans ,exponential,100,1,0.631,0.244,1.453,0.631,0.201,0.145,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",97f9c
2023-09-06 19:03:27,f3d54,8,GMM random,exponential,100,1,0.77,0.195,1.26,0.77,370.775,0.707,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",31100000
2023-09-06 19:03:29,a358d,8,MLP kmeans ,exponential,100,1,0.976,0.063,0.223,0.983,0.013,0.008,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",31100000
2023-09-06 19:07:17,39b18,8,GMM random,multivariate,100,1,0.135,0.033,0.163,0.135,207.095,0.552,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",0929a
2023-09-06 19:07:26,c324f,8,MLP kmeans ,multivariate,100,1,0.235,0.031,0.118,0.241,0.036,0.455,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",0929a
2023-09-06 19:08:08,2f98c,8,GMM random,exponential,1000,1,0.924,0.103,1.193,0.924,548.228,1.013,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",b4660
2023-09-06 19:09:53,3d76f,8,MLP kmeans ,exponential,1000,1,0.948,0.085,1.262,0.948,0.032,0.023,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",b4660
2023-09-06 19:10:22,92bad,8,GMM kmeans,exponential,1000,1,0.909,0.113,1.173,0.909,543.521,1.013,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",b4660
2023-09-06 19:11:36,9427f,4,GMM kmeans,exponential,100,1,0.73,0.211,1.223,0.73,374.505,0.707,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",311e5
2023-09-06 19:11:44,98a8f,4,MLP kmeans ,exponential,100,1,0.964,0.077,0.287,0.966,0.019,0.017,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",311e5
2023-09-06 19:12:03,81e27,32,GMM kmeans,exponential,100,1,-1.039,0.58,6.123,-1.039,680.39,nan,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",311e5
2023-09-06 19:12:21,86991,32,MLP kmeans ,exponential,100,1,0.887,0.137,0.661,0.923,0.06,0.107,{},"{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",311e5
