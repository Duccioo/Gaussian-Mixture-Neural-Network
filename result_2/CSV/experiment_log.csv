Date,Id,Components,Model,Pdf Type,Samples,Dimension,R2 Score,Mse Score,Max Error Score,Evs Score,Ise Score,K1 Score,Best Params,Experiment Params,Epoch,Pdf Param,Id Dataset
2023-09-08 17:02:06,88814,4,GMM random,exponential,100,1,0.785,0.185,1.129,0.785,361.084,0.702,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:02:07,19fe8,4,MLP kmeans ,exponential,100,1,0.933,0.103,0.438,0.935,0.034,0.029,"{'criterion': <class 'torch.nn.modules.loss.MSELoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.005, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.MSELoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.005, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:04:08,c77f9,8,GMM random,exponential,100,1,0.793,0.182,1.131,0.793,362.027,0.702,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:04:09,874b6,8,MLP kmeans ,exponential,100,1,0.963,0.077,0.28,0.973,0.019,0.012,"{'criterion': <class 'torch.nn.modules.loss.MSELoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.MSELoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:06:51,ec961,8,MLP kmeans ,exponential,100,1,0.973,0.066,0.244,0.981,0.014,0.009,"{'criterion': <class 'torch.nn.modules.loss.MSELoss'>, 'max_epochs': 50, 'batch_size': 8, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.MSELoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:07:04,f1a80,8,MLP kmeans ,exponential,100,1,0.955,0.084,0.337,0.967,0.023,0.018,"{'criterion': <class 'torch.nn.modules.loss.MSELoss'>, 'max_epochs': 60, 'batch_size': 8, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.MSELoss'>], 'max_epochs': [60, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",60,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:07:13,f207c,8,MLP kmeans ,exponential,100,1,0.982,0.054,0.277,0.988,0.009,0.006,"{'criterion': <class 'torch.nn.modules.loss.MSELoss'>, 'max_epochs': 40, 'batch_size': 8, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.MSELoss'>], 'max_epochs': [40, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",40,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:07:33,ab3e6,8,MLP kmeans ,exponential,100,1,0.982,0.053,0.278,0.989,0.009,0.006,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 40, 'batch_size': 8, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [40, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",40,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:07:43,8b646,8,MLP kmeans ,exponential,100,1,0.974,0.065,0.236,0.982,0.013,0.008,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 8, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:07:55,73c19,8,MLP kmeans ,exponential,100,1,0.981,0.056,0.244,0.987,0.01,0.006,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 45, 'batch_size': 8, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [45, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",45,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:08:05,aa046,8,MLP kmeans ,exponential,100,1,0.967,0.073,0.345,0.982,0.017,0.037,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 30, 'batch_size': 8, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [30, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",30,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:08:16,d3a85,8,MLP kmeans ,exponential,100,1,0.976,0.062,0.311,0.986,0.012,0.018,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 35, 'batch_size': 8, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [35, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",35,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:08:26,95c49,32,GMM random,exponential,100,1,0.793,0.182,1.131,0.793,362.181,0.702,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:08:26,bcc59,32,MLP kmeans ,exponential,100,1,0.891,0.132,0.595,0.937,0.056,0.161,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 35, 'batch_size': 8, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [35, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",35,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:08:39,bad6f,32,MLP kmeans ,exponential,100,1,0.893,0.131,0.598,0.938,0.055,0.157,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 8, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:08:56,21fec,32,MLP kmeans ,exponential,100,1,0.897,0.128,0.609,0.936,0.052,0.102,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:09:06,4ea9d,32,MLP kmeans ,exponential,100,1,0.896,0.129,0.604,0.936,0.053,0.111,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 40, 'batch_size': 4, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [40, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",40,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:09:45,9e234,32,MLP kmeans ,exponential,100,1,0.897,0.128,0.609,0.936,0.052,0.102,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.2}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:09:54,e17cd,32,MLP kmeans ,exponential,100,1,0.897,0.128,0.609,0.936,0.052,0.102,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:10:06,dd5d3,32,MLP kmeans ,exponential,100,1,0.897,0.128,0.625,0.936,0.053,0.095,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 60, 'batch_size': 4, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [60, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",60,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:10:22,e4cf7,32,MLP kmeans ,exponential,100,1,0.892,0.132,0.689,0.931,0.055,0.096,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 80, 'batch_size': 4, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [80, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",80,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:10:33,52541,32,MLP kmeans ,exponential,100,1,0.888,0.134,0.643,0.935,0.057,0.167,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 80, 'batch_size': 8, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [80, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",80,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:10:47,f609c,32,MLP kmeans ,exponential,100,1,0.897,0.129,0.707,0.93,0.053,0.089,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 80, 'batch_size': 2, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [80, 1000, 5000], 'batch_size': [2, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",80,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:10:58,05df0,32,MLP kmeans ,exponential,100,1,0.902,0.125,0.613,0.934,0.05,0.08,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 2, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [2, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:11:07,a4503,32,MLP kmeans ,exponential,100,1,0.908,0.121,0.586,0.941,0.047,0.134,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 2, 'lr': 0.003, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [2, 32, 16], 'lr': [0.003, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:11:19,6030a,32,MLP kmeans ,exponential,100,1,0.916,0.116,0.528,0.955,0.043,0.295,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 2, 'lr': 0.005, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.2}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [2, 32, 16], 'lr': [0.005, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:11:37,5a89f,32,MLP kmeans ,exponential,100,1,0.894,0.13,0.605,0.934,0.054,0.138,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 2, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.2}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [2, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.2, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:11:51,59948,32,MLP kmeans ,exponential,100,1,0.901,0.126,0.599,0.929,0.051,0.104,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 40, 'batch_size': 2, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [40, 1000, 5000], 'batch_size': [2, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",40,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:12:40,d0fea,4,MLP kmeans ,exponential,100,1,0.956,0.083,0.284,0.958,0.022,0.024,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 40, 'batch_size': 2, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [40, 1000, 5000], 'batch_size': [2, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",40,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:12:55,39617,4,MLP kmeans ,exponential,100,1,0.955,0.085,0.315,0.955,0.023,0.018,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 2, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [2, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:13:04,f002c,4,MLP kmeans ,exponential,100,1,0.964,0.076,0.287,0.966,0.019,0.017,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:13:13,63885,4,MLP kmeans ,exponential,100,1,0.942,0.096,0.411,0.948,0.03,0.02,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.003, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.003, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:13:21,0d4d9,4,MLP kmeans ,exponential,100,1,0.97,0.07,0.378,0.982,0.016,0.013,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:13:30,7a3b9,4,MLP kmeans ,exponential,100,1,0.975,0.064,0.359,0.98,0.013,0.007,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 60, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [60, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",60,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:13:50,a1172,4,MLP kmeans ,exponential,100,1,0.971,0.068,0.393,0.973,0.015,0.011,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 70, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [70, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",70,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:14:01,b6fef,4,MLP kmeans ,exponential,100,1,0.961,0.079,0.546,0.962,0.02,0.011,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 80, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [80, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",80,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:14:25,498a9,4,MLP kmeans ,exponential,100,1,0.973,0.065,0.365,0.976,0.014,0.01,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 65, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [65, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",65,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:14:37,bc91e,4,MLP kmeans ,exponential,100,1,0.977,0.061,0.321,0.985,0.012,0.008,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 65, 'batch_size': 8, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [65, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",65,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:14:46,164ac,4,MLP kmeans ,exponential,100,1,0.966,0.074,0.373,0.981,0.017,0.039,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 8, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:14:56,9cb96,4,MLP kmeans ,exponential,100,1,0.974,0.065,0.325,0.976,0.013,0.01,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 90, 'batch_size': 8, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(80, ReLU()), (160, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [90, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(80, ReLU()), (160, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",90,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:15:07,956e2,4,MLP kmeans ,exponential,100,1,0.975,0.063,0.267,0.976,0.013,0.019,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 90, 'batch_size': 8, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(128, ReLU()), (128, Tanh())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [90, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, Tanh())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",90,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:15:14,9aea2,4,MLP kmeans ,exponential,100,1,0.964,0.076,0.305,0.967,0.018,0.01,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 90, 'batch_size': 8, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [90, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (8, ReLU())], [(128, ReLU()), (128, Tanh())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",90,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:15:25,aafff,4,MLP kmeans ,exponential,100,1,0.969,0.07,0.268,0.972,0.016,0.01,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 90, 'batch_size': 8, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [90, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",90,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:15:33,3d7c5,4,MLP kmeans ,exponential,100,1,0.96,0.079,0.308,0.964,0.02,0.014,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 90, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [90, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",90,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:15:43,51ac4,4,MLP kmeans ,exponential,100,1,0.977,0.061,0.329,0.979,0.012,0.012,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:15:53,f06d1,4,MLP kmeans ,exponential,100,1,0.949,0.09,0.35,0.958,0.026,0.016,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.1}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.1, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:16:04,537af,4,MLP kmeans ,exponential,100,1,0.977,0.061,0.329,0.979,0.012,0.012,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:16:14,dea50,32,MLP kmeans ,exponential,100,1,0.894,0.13,0.622,0.935,0.054,0.093,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:16:24,c0455,32,MLP kmeans ,exponential,100,1,0.91,0.12,0.596,0.943,0.046,0.059,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(128, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU())], [(16, ReLU()), (32, ReLU()), (16, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:16:38,91696,32,MLP kmeans ,exponential,100,1,0.891,0.132,0.607,0.936,0.056,0.157,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(128, ReLU()), (128, Tanh())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(128, ReLU()), (128, Tanh())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:16:52,958c7,32,MLP kmeans ,exponential,100,1,0.887,0.134,0.609,0.933,0.057,0.155,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:17:03,d9c17,32,MLP kmeans ,exponential,100,1,0.91,0.12,0.598,0.945,0.046,0.065,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(64, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(64, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:17:10,e69c5,32,MLP kmeans ,exponential,100,1,0.911,0.119,0.618,0.937,0.045,0.031,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 8, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(64, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 1000, 5000], 'batch_size': [8, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(64, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:17:18,e5eba,32,MLP kmeans ,exponential,100,1,0.911,0.119,0.579,0.949,0.045,0.087,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 60, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(64, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [60, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.001, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(64, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",60,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:17:23,82b7e,32,MLP kmeans ,exponential,100,1,0.91,0.12,0.552,0.954,0.046,0.144,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 60, 'batch_size': 4, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(64, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [60, 1000, 5000], 'batch_size': [4, 32, 16], 'lr': [0.002, 0.002], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(64, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",60,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:23:37,81d3e,32,MLP kmeans ,exponential,100,1,0.897,0.128,0.644,0.905,0.053,0.036,"{'batch_size': 8, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.005, 'max_epochs': 60, 'module__dropout': 0.3, 'module__hidden_layer': [(128, ReLU()), (128, ReLU()), (128, ReLU())], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [60, 40, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(64, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",60,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:34:07,ba723,32,MLP kmeans ,exponential,100,1,0.911,0.119,0.579,0.949,0.045,0.087,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 60, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(64, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [60, 40, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(64, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",60,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-08 17:56:30,1162b,4,MLP random ,exponential,100,1,0.759,0.196,1.076,0.759,0.123,0.132,"{'batch_size': 4, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.005, 'max_epochs': 70, 'module__dropout': 0.1, 'module__hidden_layer': [(64, Tanh()), (32, Tanh()), (128, ReLU())], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [70, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(64, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",70,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 01:31:17,26683,4,MLP random ,exponential,100,1,0.954,0.086,0.328,0.97,0.024,0.134,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 70, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(64, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [70, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(64, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",70,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 01:37:17,534f1,32,MLP random ,exponential,100,1,0.759,0.196,0.953,0.762,0.123,0.153,"{'batch_size': 4, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.005, 'max_epochs': 70, 'module__dropout': 0.1, 'module__hidden_layer': [(64, Tanh()), (32, Tanh()), (128, ReLU())], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [70, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(64, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",70,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 02:21:36,e3542,32,MLP random ,exponential,100,1,0.944,0.095,0.309,0.964,0.029,0.181,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 70, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(64, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [70, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(64, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",70,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 02:21:57,26e86,32,MLP random ,exponential,100,1,0.958,0.081,0.321,0.973,0.021,0.109,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 70, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(32, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [70, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(32, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",70,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 02:22:18,999e5,32,MLP random ,exponential,100,1,0.965,0.075,0.311,0.974,0.018,0.06,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 70, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [70, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",70,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 02:22:28,77484,32,MLP random ,exponential,100,1,0.967,0.073,0.404,0.969,0.017,0.03,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 70, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(8, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [70, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(8, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",70,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 02:22:59,7ebe2,32,MLP random ,exponential,100,1,-0.619,0.509,0.656,0.456,0.825,0.541,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 70, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(4, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [70, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(4, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",70,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 02:23:13,064b7,32,MLP random ,exponential,100,1,0.968,0.071,0.342,0.974,0.016,0.04,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 60, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [60, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",60,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 02:23:23,208cd,32,MLP random ,exponential,100,1,0.97,0.07,0.387,0.972,0.015,0.019,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 02:24:19,b6366,32,MLP random ,exponential,100,1,0.963,0.077,0.29,0.974,0.019,0.072,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 40, 'batch_size': 4, 'lr': 0.002, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [40, 30, 50], 'batch_size': [4, 8], 'lr': [0.002, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",40,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 02:24:29,2b106,32,MLP random ,exponential,100,1,0.96,0.08,0.452,0.96,0.021,0.01,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 40, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [40, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",40,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 02:24:40,dbce9,32,MLP random ,exponential,100,1,0.963,0.076,0.3,0.974,0.019,0.067,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.0015, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 30, 50], 'batch_size': [4, 8], 'lr': [0.0015, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-09-09 02:26:09,df5ab,32,GMM random,logistic,100,1,0.134,0.033,0.164,0.134,206.802,0.552,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",bbcdf
2023-09-09 02:26:12,5cd70,32,MLP random ,logistic,100,1,-7.002,0.101,0.306,-6.801,0.379,9.588,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",bbcdf
2023-09-09 02:26:50,2215f,32,MLP kmeans ,logistic,100,1,-6.891,0.1,0.304,-6.701,0.374,9.719,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 50, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [50, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",50,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",bbcdf
2023-09-09 02:27:28,26cbb,32,MLP kmeans ,logistic,100,1,-3.57,0.076,0.23,-3.569,0.216,12.289,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 90, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [90, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",90,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",bbcdf
2023-09-09 02:27:50,5b276,16,GMM random,logistic,100,1,0.133,0.033,0.164,0.134,206.774,0.552,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",bbcdf
2023-09-09 02:28:04,74d4b,16,MLP kmeans ,logistic,100,1,-3.578,0.076,0.229,-3.577,0.217,11.905,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 90, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [90, 30, 50], 'batch_size': [4, 8], 'lr': [0.001, 0.0015, 0.002, 0.005], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",90,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",bbcdf
2023-09-09 14:54:53,b50b7,16,MLP kmeans ,logistic,100,1,-26.959,0.188,0.479,-22.903,1.324,5.501,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 10, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [10, 100, 1000], 'batch_size': [4, 8, 16], 'lr': [0.001, 0.003], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",10,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",bbcdf
2023-09-09 15:22:19,2941e,16,MLP kmeans ,logistic,100,1,0.509,0.025,0.09,0.516,0.023,0.587,"{'batch_size': 8, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.001, 'max_epochs': 1000, 'module__dropout': 0.3, 'module__hidden_layer': [(128, ReLU()), (128, ReLU()), (128, ReLU())], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [10, 100, 1000], 'batch_size': [4, 8, 16], 'lr': [0.001, 0.003], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",1000,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",bbcdf
2023-09-09 15:50:23,48fac,16,MLP random ,logistic,100,1,0.133,0.033,0.163,0.133,0.041,0.425,"{'batch_size': 4, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.001, 'max_epochs': 1000, 'module__dropout': 0.3, 'module__hidden_layer': [(128, ReLU()), (128, ReLU()), (128, ReLU())], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [10, 100, 1000], 'batch_size': [4, 8, 16], 'lr': [0.001, 0.003], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",1000,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",bbcdf
2023-09-09 15:50:58,5fff7,16,GMM kmeans,logistic,100,1,-0.19,0.039,1.869,-0.19,549.052,0.552,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 30, 'scale': 1, 'weight': 0.2}]]",bbcdf
2023-09-09 16:32:17,1c079,16,GMM kmeans,logistic,100,1,-0.007,0.041,1.869,-0.007,588.903,0.688,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",bd572
2023-09-09 16:32:30,4a638,16,MLP kmeans ,logistic,100,1,-21.893,0.196,0.479,-18.376,1.339,4.767,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 10, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [10, 100, 1000], 'batch_size': [4, 8, 16], 'lr': [0.001, 0.003], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",10,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",bd572
2023-09-09 16:33:24,d1200,8,GMM kmeans,logistic,100,1,0.912,0.012,0.07,0.912,380.166,0.688,None,None,0,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",bd572
2023-09-09 17:00:03,ec9b0,8,MLP kmeans ,logistic,100,1,0.871,0.015,0.052,0.878,0.008,0.285,"{'batch_size': 4, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.001, 'max_epochs': 1000, 'module__dropout': 0.1, 'module__hidden_layer': [(128, ReLU()), (128, ReLU()), (128, ReLU())], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [10, 100, 1000], 'batch_size': [4, 8, 16], 'lr': [0.001, 0.003], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",1000,"[[{'type': 'logistic', 'mean': 20, 'scale': 0.5, 'weight': 0.4}, {'type': 'logistic', 'mean': 10, 'scale': 4, 'weight': 0.4}, {'type': 'logistic', 'mean': 17, 'scale': 1, 'weight': 0.2}]]",bd572
2023-10-17 18:22:36,7564f,4,GMM kmeans,exponential,100,1,0.749,0.2,1.11,0.749,365.673,0.702,None,None,0,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-10-17 18:22:37,39edf,4,MLP kmeans ,exponential,100,1,0.4,0.31,0.828,0.591,0.306,0.364,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 10, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [10, 100, 1000], 'batch_size': [4, 8, 16], 'lr': [0.001, 0.003], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",10,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-10-17 18:24:04,eb696,4,MLP kmeans ,exponential,100,1,0.969,0.071,0.311,0.98,0.016,0.057,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 100, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 100, 1000], 'batch_size': [4, 8, 16], 'lr': [0.001, 0.003], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'mean': 0.6, 'weight': 1}]]",297d0
2023-10-17 18:26:03,4aaad,4,GMM kmeans,Multimodal 1254,100,1,-0.064,0.057,0.2,-0.064,83.169,0.161,None,None,0,"[[{'type': 'exponential', 'rate': 1, 'weight': 0.2}, {'type': 'logistic', 'mean': 4, 'scale': 0.8, 'weight': 0.25}, {'type': 'logistic', 'mean': 5.5, 'scale': 0.7, 'weight': 0.3}, {'type': 'exponential', 'mean': -1, 'weight': 0.25, 'shift': -10}]]",e83ad
2023-10-17 18:26:11,253a8,4,MLP kmeans ,Multimodal 1254,100,1,-0.049,0.057,0.094,0.083,0.032,0.144,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 100, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 100, 1000], 'batch_size': [4, 8, 16], 'lr': [0.001, 0.003], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'rate': 1, 'weight': 0.2}, {'type': 'logistic', 'mean': 4, 'scale': 0.8, 'weight': 0.25}, {'type': 'logistic', 'mean': 5.5, 'scale': 0.7, 'weight': 0.3}, {'type': 'exponential', 'mean': -1, 'weight': 0.25, 'shift': -10}]]",e83ad
2023-10-17 18:28:57,e52a6,4,MLP kmeans ,Multimodal 1254,100,1,0.181,0.05,0.101,0.305,0.025,0.117,"{'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'max_epochs': 100, 'batch_size': 4, 'lr': 0.001, 'module__last_activation': 'lambda', 'module__hidden_layer': [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], 'optimizer': <class 'torch.optim.adam.Adam'>, 'module__dropout': 0.3}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [100, 100, 1000], 'batch_size': [4, 8, 16], 'lr': [0.001, 0.003], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",100,"[[{'type': 'exponential', 'rate': 1, 'weight': 0.2}, {'type': 'logistic', 'mean': 4, 'scale': 0.8, 'weight': 0.25}, {'type': 'logistic', 'mean': 5.5, 'scale': 0.7, 'weight': 0.3}, {'type': 'exponential', 'mean': -1, 'weight': 0.25, 'shift': -10}]]",e83ad
2023-10-17 19:03:35,85d2f,4,MLP kmeans ,Multimodal 1254,100,1,0.57,0.036,0.131,0.57,0.013,0.075,"{'batch_size': 4, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.001, 'max_epochs': 1000, 'module__dropout': 0.1, 'module__hidden_layer': [(128, ReLU()), (64, Tanh()), (32, ReLU())], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [10, 100, 1000], 'batch_size': [4, 8, 16], 'lr': [0.001, 0.003], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",1000,"[[{'type': 'exponential', 'rate': 1, 'weight': 0.2}, {'type': 'logistic', 'mean': 4, 'scale': 0.8, 'weight': 0.25}, {'type': 'logistic', 'mean': 5.5, 'scale': 0.7, 'weight': 0.3}, {'type': 'exponential', 'mean': -1, 'weight': 0.25, 'shift': -10}]]",e83ad
2023-10-17 20:08:20,8d7d2,4,GMM random,Multimodal 1254,100,1,-0.11,0.058,0.202,-0.099,41.83,0.161,None,None,0,"[[{'type': 'exponential', 'rate': 1, 'weight': 0.2}, {'type': 'logistic', 'mean': 4, 'scale': 0.8, 'weight': 0.25}, {'type': 'logistic', 'mean': 5.5, 'scale': 0.7, 'weight': 0.3}, {'type': 'exponential', 'mean': -1, 'weight': 0.25, 'shift': -10}]]",e83ad
2023-10-17 20:35:28,8b58e,4,MLP random ,Multimodal 1254,100,1,-0.143,0.059,0.202,-0.13,0.034,0.237,"{'batch_size': 16, 'criterion': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.001, 'max_epochs': 1000, 'module__dropout': 0.3, 'module__hidden_layer': [(128, ReLU()), (64, Tanh()), (32, ReLU())], 'module__last_activation': 'lambda', 'optimizer': <class 'torch.optim.adam.Adam'>}","{'criterion': [<class 'torch.nn.modules.loss.HuberLoss'>], 'max_epochs': [10, 100, 1000], 'batch_size': [4, 8, 16], 'lr': [0.001, 0.003], 'module__last_activation': ['lambda'], 'module__hidden_layer': [[(16, ReLU())], [(16, ReLU()), (32, ReLU()), (32, ReLU()), (16, ReLU())], [(128, ReLU()), (128, Tanh())], [(80, ReLU()), (160, ReLU())], [(128, ReLU()), (128, ReLU()), (128, ReLU())], [(64, Tanh()), (32, Tanh()), (128, ReLU())], [(32, LeakyReLU(negative_slope=0.01)), (32, Tanh()), (64, ReLU())], [(128, ReLU()), (64, Tanh()), (32, ReLU())]], 'optimizer': [<class 'torch.optim.adam.Adam'>], 'module__dropout': [0.3, 0.1]}",1000,"[[{'type': 'exponential', 'rate': 1, 'weight': 0.2}, {'type': 'logistic', 'mean': 4, 'scale': 0.8, 'weight': 0.25}, {'type': 'logistic', 'mean': 5.5, 'scale': 0.7, 'weight': 0.3}, {'type': 'exponential', 'mean': -1, 'weight': 0.25, 'shift': -10}]]",e83ad
